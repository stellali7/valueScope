{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Training Data Generation\n",
    "- Each topical group of subreddits and norm dimension has a dedicated classifier model (e.g. DeBerta-base-v3), enabling a comparison across these similar subreddits. To train such models, we generate synthetic labels via GPT-4 through stratified sampling and automatic labeling.\n",
    "- During the sampling stage, we employ GPT-3.5 to rate comments on a 5-point Likert Scale to gauge normness. For a particular subreddit, we rate up to 10K comments or until we obtain at least 10 comments per likert scale value (whichever happens first). In the case we rate up to 10K comments without obtaining 10 comments per scale value, we randomly sample comments from the nearest scale value (e.g. if we have only 4 comments for likert scale value of 5, then we randomly sample 6 comments from likert scale value of 4). We repeat this process for each norm dimension.\n",
    "- For a particular norm dimension, this results in 150 comments per topic (200 for Finance, which contains 4 subreddits) since 10 comments per scale x 5 likert scale x n subreddits = 50 * n comments. \n",
    "- For a particular topic and norm dimension, 1,250 comment pairs are randomly selected to create binary synthetic labels using GPT-4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import prompts\n",
    "\n",
    "# using this random seed\n",
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Keys\n",
    "OPENAI_KEY = \"\"  # insert your own key here\n",
    "client = OpenAI(api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains all the processed subreddit data dumps\n",
    "PROCESSED_DATA_DIRECTORY = \"/gscratch/argon/hjung10/norm_discovery_project/data/data_dump/\"\n",
    "\n",
    "# contains the pkl file that can be loaded as a dictionary; contains all subreddits\n",
    "SAMPLED_COMMENTS_PER_SUBREDDIT_DIRECTORY = \"/home/hjung10/norm_discovery/synthetic_data/subreddit_data_sample/\"\n",
    "\n",
    "# contains comments rated on the 5-point scale value per dimension per subreddit\n",
    "SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY = \"/home/hjung10/norm_discovery/synthetic_data/scale_rated_samples/\"\n",
    "\n",
    "# contains all pairwise comparisons between the sampled comments\n",
    "PAIRWISE_COMPARISONS_DIRECTORY = \"/home/hjung10/norm_discovery/synthetic_data/pairwise_comparison/\"\n",
    "\n",
    "# contains all synthetic labeled data\n",
    "SYNTHETIC_DATA_DIRECTORY = \"/home/hjung10/norm_discovery/synthetic_data/synthetic_labels/\"\n",
    "\n",
    "# desired subreddits and sampling amount\n",
    "subreddit_lists = ['democrats', 'republican', 'libertarian']  # politics\n",
    "#subreddit_lists = [\"askmen\", \"askwomen\", \"asktransgender\"]   # gender\n",
    "#subreddit_lists = [\"askscience\", \"shittyaskscience\", \"asksciencediscussion\"]   # science\n",
    "#subreddit_lists = [\"stocks\", \"wallstreetbets\", \"wallstreetbetsnew\", \"pennystocks\"]   # finance\n",
    "\n",
    "SAMPLE_LIMIT_PER_SUBREDDIT = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling 10K random comments per subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples the provided amount of comments from each of target_subreddits. \n",
    "def select_comments(target_subreddits, filter_upvotes_bool): # true if you want to filter by the upvote\n",
    "    selected = {subreddit: [] for subreddit in target_subreddits}\n",
    "\n",
    "    for subreddit in target_subreddits:\n",
    "        sys.stdout.write(f'[{time.strftime(\"%Y-%m-%d %H:%M:%S\")}] r/{subreddit}: start random comment selection\\n')\n",
    "        logging.info(f\"r/{subreddit}: start random comment selection\")\n",
    "        done = False\n",
    "        selected_comments_id, disselected_comments_id = [], []\n",
    "        with open(os.path.join(PROCESSED_DATA_DIRECTORY, f\"comments_{subreddit}.pkl\"), \"rb\") as f:\n",
    "            data_comments = pickle.load(f)\n",
    "        sys.stdout.write(f'[{time.strftime(\"%Y-%m-%d %H:%M:%S\")}] r/{subreddit}: number of comments total: {len(data_comments)}\\n')\n",
    "        logging.info(f\"r/{subreddit}: number of comments total: {len(data_comments)}\")\n",
    "        while not done:\n",
    "            rand_ind = random.randint(0, len(data_comments)-1)\n",
    "            if rand_ind in selected_comments_id or rand_ind in disselected_comments_id:\n",
    "                continue\n",
    "            if filter_upvotes_bool and (data_comments[rand_ind][\"score\"] < upvote_score_threshold):    # changed to get comments that got more than 5 upvote\n",
    "                disselected_comments_id.append(rand_ind)\n",
    "                continue\n",
    "            selected_comments_id.append(rand_ind)\n",
    "            selected[subreddit].append(data_comments[rand_ind])\n",
    "            if len(selected[subreddit]) >= SAMPLE_LIMIT_PER_SUBREDDIT or len(selected_comments_id) + len(disselected_comments_id) >= len(data_comments):\n",
    "                done = True\n",
    "        sys.stdout.write(f'[{time.strftime(\"%Y-%m-%d %H:%M:%S\")}] r/{subreddit}: done selecting {len(selected[subreddit])} comments.\\n')\n",
    "        logging.info(f\"{subreddit}: done selecting {len(selected[subreddit])} comments.\")\n",
    "    return selected\n",
    "\n",
    "# obtains the corresponding submission titles and body of the selected comments\n",
    "# accepts the comments argument based on the select_comments function outputs\n",
    "def fetch_submission_texts(selected_comments):\n",
    "    comments_and_submission = {subreddit: [] for subreddit in selected_comments.keys()}\n",
    "\n",
    "    # iterate through each subreddit\n",
    "    for subreddit, comments_list in selected_comments.items():\n",
    "\n",
    "        # reading the submissions data from the particular subreddit\n",
    "        data_submissions = \"\"\n",
    "        with open(os.path.join(PROCESSED_DATA_DIRECTORY, f\"submissions_{subreddit}.pkl\"), \"rb\") as f:\n",
    "            data_submissions = pickle.load(f)\n",
    "\n",
    "        # per comment, find the matching id to the submission\n",
    "        for comment in comments_list:\n",
    "            submission_id = comment['parent_id'].split(\"_\")[1] \n",
    "\n",
    "            # find the submission that matches the comment's submission_id\n",
    "            for submission in data_submissions: \n",
    "                if submission_id == submission[\"id\"]:\n",
    "                    \n",
    "                    title = submission[\"title\"]\n",
    "                    body = submission[\"selftext\"]\n",
    "                    \n",
    "                    comments_and_submission[subreddit].append((comment, title, body, submission))\n",
    "        print(\"Completed \" + subreddit)\n",
    "    return comments_and_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 04:19:35] r/askmen: start random comment selection\n",
      "[2024-03-11 04:21:04] r/askmen: number of comments total: 4679855\n",
      "[2024-03-11 04:21:07] r/askmen: done selecting 25000 comments.\n",
      "[2024-03-11 04:21:07] r/askmenover30: start random comment selection\n",
      "[2024-03-11 04:21:19] r/askmenover30: number of comments total: 184136\n",
      "[2024-03-11 04:21:22] r/askmenover30: done selecting 25000 comments.\n",
      "[2024-03-11 04:21:22] r/askwomen: start random comment selection\n",
      "[2024-03-11 04:22:04] r/askwomen: number of comments total: 2246255\n",
      "[2024-03-11 04:22:07] r/askwomen: done selecting 25000 comments.\n",
      "[2024-03-11 04:22:07] r/askwomenover30: start random comment selection\n",
      "[2024-03-11 04:22:31] r/askwomenover30: number of comments total: 362467\n",
      "[2024-03-11 04:22:34] r/askwomenover30: done selecting 25000 comments.\n",
      "[2024-03-11 04:22:34] r/asktransgender: start random comment selection\n",
      "[2024-03-11 04:22:46] r/asktransgender: number of comments total: 676563\n",
      "[2024-03-11 04:22:49] r/asktransgender: done selecting 25000 comments.\n"
     ]
    }
   ],
   "source": [
    "# selecting 50K random comments from each subreddit\n",
    "selected = select_comments(subreddit_lists, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching their corresponding submission post (titles and descriptions)\n",
    "comments_and_submission = fetch_submission_texts(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary to sampled_comments_and_submissions.pkl file\n",
    "with open(SAMPLED_COMMENTS_PER_SUBREDDIT_DIRECTORY + 'sampled_comments_and_submissions.pkl', 'wb') as fp:\n",
    "    pickle.dump(comments_and_submission, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing into dataframe format to create prompt message\n",
    "dimensions = [\"formality\", \"supportiveness\", \"sarcasm\", \"politeness\", \"humor\"]\n",
    "\n",
    "for subreddit, comment_submission in comments_and_submission.items():\n",
    "\n",
    "    title_list = []\n",
    "    description_list = []\n",
    "    comment_list = []\n",
    "    dimension_list = []\n",
    "    comment_metadata_list = []\n",
    "    post_metadata_list = []\n",
    "    \n",
    "    # each element contains (comment, title, body, submission)\n",
    "    for comment_data in comment_submission:\n",
    "        title = comment_data[1]\n",
    "        description = comment_data[2]\n",
    "        comment = comment_data[0][\"body\"]\n",
    "\n",
    "        for dimension in dimensions:\n",
    "            title_list.append(title)\n",
    "            description_list.append(description)\n",
    "            comment_list.append(comment)\n",
    "            dimension_list.append(dimension)\n",
    "            comment_metadata_list.append(comment_data[0])\n",
    "            post_metadata_list.append(comment_data[3])\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df[\"title\"] = title_list\n",
    "    df[\"description\"] = description_list\n",
    "    df[\"comment\"] = comment_list\n",
    "    df[\"dimension\"] = dimension_list\n",
    "    df[\"comment_metadata\"] = comment_metadata_list\n",
    "    df[\"submission_metadata\"] = post_metadata_list\n",
    "    df.to_csv(SAMPLED_COMMENTS_PER_SUBREDDIT_DIRECTORY + subreddit + \"_processed_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employing GPT3.5 to rate comments\n",
    "- Rating the randomly sampled comments per subreddit until we hit at least 10 comments per scale value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_message_rating(annotation_df, few_shot):\n",
    "    dimension_to_tuple = defaultdict(list)\n",
    "    for i, row in annotation_df.iterrows():\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"description\"] if row[\"description\"] == row[\"description\"] else \"\"\n",
    "        comment = row[\"comment\"]\n",
    "        dimension_ = row[\"dimension\"]\n",
    "        few_shot_examples = \"\"\n",
    "        if dimension_ == \"formality\":\n",
    "            template = prompts.casual_formal\n",
    "            dimension = prompts.dimensions[1]\n",
    "            few_shot_examples = prompts.few_shot_rate_formality\n",
    "        elif dimension_ == \"supportiveness\":\n",
    "            template = prompts.supportive_toxic\n",
    "            dimension = prompts.dimensions[2]\n",
    "            few_shot_examples = prompts.few_shot_rate_supportive\n",
    "        elif dimension_ == \"sarcasm\":\n",
    "            template = prompts.genuine_sarcasm\n",
    "            dimension = prompts.dimensions[3]\n",
    "            few_shot_examples = prompts.few_shot_rate_genuine\n",
    "        elif dimension_ == \"politeness\":\n",
    "            template = prompts.rude_polite\n",
    "            dimension = prompts.dimensions[4]\n",
    "            few_shot_examples = prompts.few_shot_rate_polite\n",
    "        elif dimension_ == \"humor\":\n",
    "            template = prompts.humor_serious\n",
    "            dimension = prompts.dimensions[5]\n",
    "            few_shot_examples = \"\"\n",
    "        \n",
    "        system_content = prompts.prompt_system\n",
    "        user_content = \"\"\n",
    "        if few_shot:\n",
    "            user_content = prompts.prompt_few_shot_rate\n",
    "            user_content = user_content.replace(\"[FEW-SHOT]\", few_shot_examples)\n",
    "        else:\n",
    "            user_content = prompts.prompt_rate\n",
    "        user_content = user_content.replace(\"[TITLE]\", title)\n",
    "        user_content = user_content.replace(\"[DIMENSION]\", dimension)\n",
    "        user_content = user_content.replace(\"[DESCRIPTION]\", description)\n",
    "        user_content = user_content.replace(\"[COMMENT]\", comment)\n",
    "        user_content = user_content.replace(\"[DIMENSION_TEMPLATE]\", template)\n",
    "        \n",
    "        \n",
    "        messages =  [{\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content}]\n",
    "    \n",
    "        dimension_to_tuple[dimension].append((messages, title, description, comment, dimension, row[\"comment_metadata\"], row[\"submission_metadata\"]))\n",
    "    return dimension_to_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating response from gpt 3.5\n",
    "def get_response(messages, model_name):\n",
    "    ct, num_tokens = 0, 0\n",
    "    while ct < 3:\n",
    "        ct += 1\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                temperature=0.2,\n",
    "                max_tokens=512,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            num_tokens += response.usage.total_tokens\n",
    "            return response, num_tokens\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "    return None, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prediction(gpt_message_response):\n",
    "    try:\n",
    "        prediction = ''.join(gpt_message_response.split(\"[\")[1].split(\"]\")[0])\n",
    "        if \".\" in prediction:\n",
    "            prediction = prediction.split(\".\")[0]\n",
    "\n",
    "        prediction = int(prediction)\n",
    "    except:\n",
    "        print(\"extraction failed\")\n",
    "        return None\n",
    "    return prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_extract_gpt_ratings(rating_prompts, model_name, subreddit, dimension, dimension_to_scale_values, ratings_mappings):\n",
    "    failed, usage = 0, 0\n",
    "    prompts = rating_prompts[dimension]\n",
    "    \n",
    "    print(dimension)\n",
    "\n",
    "    # creating new dictionary\n",
    "    if not ratings_mappings or ratings_mappings == None:\n",
    "        print(\"Creating new dictionary\")\n",
    "        ratings_mappings = dict()\n",
    "        for i in range(1, 6):\n",
    "            ratings_mappings[i] = list()\n",
    "    else:\n",
    "        print(\"Dictionary detected\")\n",
    "\n",
    "    # iterating through the prompts until we get at least 10 comments per scale value\n",
    "    prompt_index = -1\n",
    "    total_rated = 0\n",
    "    while total_rated < 10000 and (len(ratings_mappings[1]) < 10 or len(ratings_mappings[2]) < 10 or len(ratings_mappings[3]) < 10 or len(ratings_mappings[4]) < 10 or len(ratings_mappings[5]) < 10):\n",
    "        if prompt_index >= len(prompts):\n",
    "            break\n",
    "        \n",
    "        prompt_index += 1\n",
    "        prompt_tuple = prompts[prompt_index]\n",
    "        prompt = prompt_tuple[0]\n",
    "        comment = prompt_tuple[3]\n",
    "        \n",
    "        # detecting duplicate comments, no need to rate again\n",
    "        if detect_duplicate_comments(ratings_mappings, comment):\n",
    "            continue\n",
    "        \n",
    "        response, num_tokens = get_response(prompt, model_name)\n",
    "        usage += num_tokens\n",
    "        try: \n",
    "            rewrite = response.choices[0].message.content.strip()\n",
    "        except:\n",
    "            rewrite = \"[API_ERROR]\"\n",
    "            failed += 1\n",
    "            continue\n",
    "\n",
    "        prediction = extract_prediction(rewrite)\n",
    "        if prediction == None:\n",
    "            continue\n",
    "\n",
    "        # (prediction rating, prediction, title, description, comment, dimension, row[\"comment_metadata\"], row[\"submission_metadata\"]\n",
    "        ratings_mappings[prediction].append((prediction, response, prompt_tuple[1], prompt_tuple[2], prompt_tuple[3], prompt_tuple[4], prompt_tuple[5], prompt_tuple[6]))\n",
    "\n",
    "        \n",
    "        total_rated = len(ratings_mappings[1]) + len(ratings_mappings[2]) + len(ratings_mappings[3]) + len(ratings_mappings[4]) + len(ratings_mappings[5])\n",
    "        \n",
    "        if prompt_index % 50 == 0:\n",
    "            print(\"Number of predictions with values 1: \" + str(len(ratings_mappings[1])))\n",
    "            print(\"Number of predictions with values 2: \" + str(len(ratings_mappings[2])))\n",
    "            print(\"Number of predictions with values 3: \" + str(len(ratings_mappings[3])))\n",
    "            print(\"Number of predictions with values 4: \" + str(len(ratings_mappings[4])))\n",
    "            print(\"Number of predictions with values 5: \" + str(len(ratings_mappings[5])))\n",
    "            print(\"------------\")\n",
    "            dimension_to_scale_values[dimension] = ratings_mappings\n",
    "            save_dictionary(dimension_to_scale_values, subreddit)\n",
    "            \n",
    "    if total_rated >= 10000:\n",
    "        print(\"Completed rating all 10K comments\")\n",
    "    \n",
    "    print(\"Completed obtaining at least 10 comments per scale value; next dimension\")\n",
    "    dimension_to_scale_values[dimension] = ratings_mappings\n",
    "    save_dictionary(dimension_to_scale_values, subreddit)\n",
    "    \n",
    "    return dimension_to_scale_values, failed, usage\n",
    "\n",
    "def read_dictionary(dictionary, subreddit):\n",
    "    with open(SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY + subreddit + \"_scale_rated.pkl\", 'rb') as fp:\n",
    "        dictionary = pickle.load(fp)\n",
    "    return dictionary\n",
    "\n",
    "def detect_duplicate_comments(dictionary, comment):\n",
    "    for key, values in dictionary.items():\n",
    "        for value in values:\n",
    "            if value[4] == comment or comment in value[4]:\n",
    "                #print(value[4])\n",
    "                #print(comment)\n",
    "                print(\"Duplicate comment\")\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "### various functions to save and read files easily\n",
    "\n",
    "def save_dictionary(dictionary, subreddit):\n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY + subreddit + '_scale_rated.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "        \n",
    "def save_sampled_comments(dictionary, subreddit, dimension, topic):\n",
    "    PATH_SAVE = SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY + topic + '-dimension-rated-samples/'\n",
    "    if not os.path.isdir(PATH_SAVE):\n",
    "        os.mkdir(PATH_SAVE)\n",
    "    \n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(PATH_SAVE + subreddit + '_' + dimension + '_scale_rated_samples.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "        \n",
    "# contains all 250 comments (i.e. 50 comments per subreddit * 5 gender subreddits)\n",
    "def save_sampled_comments_combined(dictionary, dimension, topic):\n",
    "    PATH_SAVE = SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY + topic + '-dimension-topic-combined/'\n",
    "    if not os.path.isdir(PATH_SAVE):\n",
    "        os.mkdir(PATH_SAVE)\n",
    "        \n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(PATH_SAVE + dimension + '_combined_' + topic + '_scale_rated_samples.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "        \n",
    "def save_sampled_comments_pairwise_combinations(dictionary, topic):\n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(PAIRWISE_COMPARISONS_DIRECTORY + topic + '_pairwise_combinations.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "        \n",
    "def save_sampled_comments_pairwise_combinations_samples(dictionary, topic, size):\n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(PAIRWISE_COMPARISONS_DIRECTORY + topic + 'sampled_' + str(size) + '_pairwise_combinations.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "        \n",
    "def read_sampled_comments_pairwise_combinations_samples(topic, size):\n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(PAIRWISE_COMPARISONS_DIRECTORY + topic + 'sampled_' + str(size) + '_pairwise_combinations.pkl', 'rb') as fp:\n",
    "        dictionary = pickle.load(fp)\n",
    "        print('dictionary read successfully from file')\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askmen\n",
      "--------------------------------\n",
      "SUPPORTIVE-TOXIC\n",
      "Number of predictions with values 1: 0\n",
      "Number of predictions with values 2: 1\n",
      "Number of predictions with values 3: 0\n",
      "Number of predictions with values 4: 0\n",
      "Number of predictions with values 5: 0\n",
      "------------\n",
      "dictionary saved successfully to file\n",
      "Number of predictions with values 1: 1\n",
      "Number of predictions with values 2: 32\n",
      "Number of predictions with values 3: 5\n",
      "Number of predictions with values 4: 10\n",
      "Number of predictions with values 5: 3\n",
      "------------\n",
      "dictionary saved successfully to file\n",
      "Number of predictions with values 1: 1\n",
      "Number of predictions with values 2: 63\n",
      "Number of predictions with values 3: 10\n",
      "Number of predictions with values 4: 21\n",
      "Number of predictions with values 5: 6\n",
      "------------\n",
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# selecting the particular subreddit, dimensions, and model you want to use to rate and sample 10K comments\n",
    "# can adjust the code in case the program crashes during the rating process (e.g. changing the dimensions list, \n",
    "# reading in dictionary that contains the results already to avoid starting from scratch)\n",
    "subreddit_ = \"stocks\"\n",
    "dimensions = [\"SUPPORTIVE-TOXIC\", \"HUMOR-SERIOUS\", \"CASUAL-FORMAL\", \"GENUINE-SARCASM\", \"RUDE-POLITE\"]  \n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "csv_file = subreddit_ + \"_processed_dataframe.csv\"\n",
    "\n",
    "subreddit_to_scale_ratings = dict()\n",
    "for subreddit in [subreddit_]:\n",
    "    print(subreddit)\n",
    "    print(\"--------------------------------\")\n",
    "    df = pd.read_csv(SAMPLED_COMMENTS_PER_SUBREDDIT_DIRECTORY + csv_file).dropna(subset=[\"comment\"])\n",
    "    rating_zero_shot = construct_message_rating(df, False)\n",
    "    \n",
    "    dimension_to_scale_values = dict()\n",
    "\n",
    "    # this code is only for resuming with another batch; comment out if first time using\n",
    "    # also pass in None value instead of dimension_to_scale_values[dimension] in the evaluate_and_extract_gpt_ratings\n",
    "    #dimension_to_scale_values = read_dictionary(dimension_to_scale_values, subreddit)\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        if dimension not in dimension_to_scale_values and len(dimension_to_scale_values) != 0:\n",
    "            dimension_to_scale_values[dimension] = None\n",
    "        \n",
    "        dimension_to_scale_values, failed, usage = evaluate_and_extract_gpt_ratings(rating_zero_shot, model_name, subreddit, dimension, dimension_to_scale_values, None)\n",
    "\n",
    "    save_dictionary(dimension_to_scale_values, subreddit)\n",
    "    subreddit_to_scale_ratings[subreddit] = dimension_to_scale_values\n",
    "    \n",
    "    print(\"Usage: \" + str(usage))\n",
    "    print(\"Failed: \" + str(failed))\n",
    "    print(\"Done with: \" + subreddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pairwise comparisons\n",
    "- For each dimension, combine the 50 comments per n subreddit, creating 50*n comments\n",
    "- Create pairwise comparisons among these 50*n comments\n",
    "- Sampling 1250 pairwise comparisons per dimension (check that the comment appears roughly 10 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[4, 16, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 18, 2]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 20, 0]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 17, 3]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 14, 6]\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "[2, 18, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[0, 20, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[0, 20, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "[0, 20, 10, 10, 10]\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 19, 1]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 19, 1]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 20, 0]\n",
      "dictionary saved successfully to file\n",
      "[10, 10, 10, 20, 0]\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# for example, if we want to generate synthetic labels for the finance topic, we would use the code below\n",
    "# to create pairwise comparisons\n",
    "dimension_combined_comments_subreddits = dict()\n",
    "subreddit_lists = ['wallstreetbets', 'wallstreetbetsnew', 'stocks', 'pennystocks']\n",
    "topic = \"finance\"\n",
    "\n",
    "for dimension in ['SUPPORTIVE-TOXIC', 'RUDE-POLITE', 'HUMOR-SERIOUS', 'GENUINE-SARCASM', 'CASUAL-FORMAL']:\n",
    "    list_dimension_combined_comments_subreddits = list()\n",
    "\n",
    "    for subreddit in subreddit_lists:\n",
    "        dict_ = dict()\n",
    "        with open(SCALE_RATED_COMMENTS_PER_SUBREDDIT_DIRECTORY + subreddit + \"_scale_rated.pkl\", 'rb') as fp:\n",
    "            dict_ = pickle.load(fp)\n",
    "\n",
    "        # only selecting supportive-toxic\n",
    "        sampled_comments = dict()\n",
    "        for scale_values, prediction_list in dict_[dimension].items():\n",
    "\n",
    "            # adding subreddit information to tuple\n",
    "            prediction_list_with_subreddit = list()\n",
    "            for prediction in prediction_list:\n",
    "                list_prediction = list(prediction)\n",
    "                list_prediction.append(subreddit)\n",
    "                edited_tuple = tuple(list_prediction)\n",
    "                \n",
    "                # filtering out posts with edits, media, etc\n",
    "                if not filter_(edited_tuple):\n",
    "                    prediction_list_with_subreddit.append(edited_tuple)\n",
    "\n",
    "            sampled_comments[scale_values] = prediction_list_with_subreddit\n",
    "\n",
    "        # confirming at least 10 comments per scale-value; checking extreme ratings (1s and 5s) and\n",
    "        # sampling from the next closest value if there's not enough\n",
    "        list_sample = [10, 10, 10, 10, 10]\n",
    "        if len(sampled_comments[1]) < 10:\n",
    "            list_sample[0] = len(sampled_comments[1])\n",
    "            list_sample[1] = (10 - len(sampled_comments[1])) + 10\n",
    "\n",
    "        if len(sampled_comments[5]) < 10:\n",
    "            list_sample[4] = len(sampled_comments[5])\n",
    "            list_sample[3] = (10 - len(sampled_comments[5])) + 10\n",
    "\n",
    "        # sampling based on the prior pass\n",
    "        print(list_sample)\n",
    "        sampled_comments_random = dict()\n",
    "        for scale_values, prediction_list in sampled_comments.items():\n",
    "            sampled = random.sample(prediction_list, k=list_sample[scale_values - 1])\n",
    "            sampled_comments_random[scale_values] = sampled\n",
    "\n",
    "            list_dimension_combined_comments_subreddits += sampled \n",
    "\n",
    "        save_sampled_comments(sampled_comments_random, subreddit, dimension, topic)\n",
    "        \n",
    "    dimension_combined_comments_subreddits[dimension] = list_dimension_combined_comments_subreddits\n",
    "    save_sampled_comments_combined(dimension_combined_comments_subreddits, dimension, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the particular dimension, we simply combine all 50 comments per subreddit (check 50 * num_subreddits)\n",
    "len(dimension_combined_comments_subreddits[dimension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19900\n",
      "19900\n",
      "19899\n",
      "19900\n",
      "19900\n",
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# creating pairwise comparisons\n",
    "dimension_pair_order_list = dict()\n",
    "for dimension, list_dimension_combined_comments in dimension_combined_comments_subreddits.items():\n",
    "    pair_order_list = list(itertools.combinations(list_dimension_combined_comments, 2))\n",
    "    \n",
    "    # confirming that the pairwise comparisons do not contain self comparisons \n",
    "    pair_order_list_duplicate_filtered = [pair for pair in pair_order_list if pair[0][4] != pair[1][4]]\n",
    "            \n",
    "    print(len(pair_order_list_duplicate_filtered))\n",
    "    dimension_pair_order_list[dimension] = pair_order_list\n",
    "\n",
    "# saving the pairwise comparisons in the file\n",
    "save_sampled_comments_pairwise_combinations(dimension_pair_order_list, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n",
      "1250\n",
      "1250\n",
      "1250\n",
      "1250\n",
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# sample 1250 pairwise comparisons out of 31125 unique comparisons for the dimension\n",
    "num_samples = 1250\n",
    "\n",
    "dimension_sampled = dict()\n",
    "for dimension, pair_order_list in dimension_pair_order_list.items():\n",
    "    sampled_pairwise_comparisons = random.sample(pair_order_list, k=num_samples)\n",
    "    print(len(sampled_pairwise_comparisons))\n",
    "    dimension_sampled[dimension] = sampled_pairwise_comparisons\n",
    "\n",
    "# saving the samples\n",
    "topic = \"finance\"\n",
    "save_sampled_comments_pairwise_combinations_samples(dimension_sampled, topic, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORTIVE-TOXIC\n",
      "Each comment appears on average: 12.5\n",
      "Each comment appears with variance of: 8.72\n",
      "Each comment appears as much as: 20\n",
      "Each comment appears as little as: 4\n",
      "RUDE-POLITE\n",
      "Each comment appears on average: 12.5\n",
      "Each comment appears with variance of: 11.23\n",
      "Each comment appears as much as: 23\n",
      "Each comment appears as little as: 6\n",
      "HUMOR-SERIOUS\n",
      "Each comment appears on average: 12.56281407035176\n",
      "Each comment appears with variance of: 15.813893588545742\n",
      "Each comment appears as much as: 37\n",
      "Each comment appears as little as: 5\n",
      "GENUINE-SARCASM\n",
      "Each comment appears on average: 12.5\n",
      "Each comment appears with variance of: 12.18\n",
      "Each comment appears as much as: 25\n",
      "Each comment appears as little as: 4\n",
      "CASUAL-FORMAL\n",
      "Each comment appears on average: 12.5\n",
      "Each comment appears with variance of: 10.06\n",
      "Each comment appears as much as: 24\n",
      "Each comment appears as little as: 4\n"
     ]
    }
   ],
   "source": [
    "# Python program to get average of a list \n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "# checking to ensure each comment appears roughly 10 times such that the model learns to generalize and learn\n",
    "# from each comment across multiple iteration\n",
    "for dimension, pair_order_list in dimension_sampled.items():\n",
    "    # building the dictionary mapping to keep track of frequency a comment has been present in the pairwise\n",
    "    comment_appearance = dict()\n",
    "    for sample_comment_data in dimension_combined_comments_subreddits[dimension]:\n",
    "        comment = sample_comment_data[4]\n",
    "        comment_appearance[comment] = 0\n",
    "\n",
    "    for pairwise in pair_order_list:\n",
    "        # choosing each of the comment in the pairwise and fetching the comment attribute in tuple\n",
    "        comment_appearance[pairwise[0][4]] +=1\n",
    "        comment_appearance[pairwise[1][4]] +=1\n",
    "\n",
    "    #print(comment_appearance)\n",
    "    #break\n",
    "    res = sum((i - Average(comment_appearance.values())) ** 2 for i in comment_appearance.values()) / len(comment_appearance.values()) \n",
    "    print(dimension)\n",
    "    print(\"Each comment appears on average: \" + str(Average(comment_appearance.values())))\n",
    "    print(\"Each comment appears with variance of: \" + str(res))\n",
    "    print(\"Each comment appears as much as: \" + str(max(comment_appearance.values())))\n",
    "    print(\"Each comment appears as little as: \" + str(min(comment_appearance.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Labeling using GPT4\n",
    "GPT4 (Definitions + No Tie Generation, Few-Shot, including ties in human annotations)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_annotation_batch_pairwise_tuples(sampled_pairwise_comparisons):\n",
    "    annotations = []\n",
    "    for pairwise in sampled_pairwise_comparisons:\n",
    "\n",
    "        score1 = pairwise[0][0]\n",
    "        response1 = pairwise[0][1]\n",
    "        title1 = pairwise[0][2]\n",
    "        description1 = pairwise[0][3]\n",
    "        comment1 = pairwise[0][4]\n",
    "        dimension = pairwise[0][5]\n",
    "        comment_metadata1 =pairwise[0][6]\n",
    "        post_metadata1 = pairwise[0][7]\n",
    "        subreddit1 = pairwise[0][8]\n",
    "        \n",
    "        score2 = pairwise[1][0]\n",
    "        response2 = pairwise[1][1]\n",
    "        title2 = pairwise[1][2]\n",
    "        description2 = pairwise[1][3]\n",
    "        comment2 = pairwise[1][4]\n",
    "        dimension = pairwise[1][5]\n",
    "        comment_metadata2 =pairwise[1][6]\n",
    "        post_metadata2 = pairwise[1][7]\n",
    "        subreddit2 = pairwise[1][8]\n",
    "   \n",
    "        example = {\"Title1\" : title1, \n",
    "                   \"Description1\" : description1,\n",
    "                   \"Comment1\" : comment1,\n",
    "                    \"Comment_Metadata1\" : comment_metadata1,\n",
    "                   \"Post_Metadata1\" : post_metadata1,\n",
    "                   \"Subreddit1\" : subreddit1,\n",
    "                   \"Score1\" : score1,\n",
    "                   \"Response1\" : response1,\n",
    "                    \"Title2\" : title2, \n",
    "                   \"Description2\" : description2,\n",
    "                   \"Comment2\" : comment2,\n",
    "                    \"Comment_Metadata2\" : comment_metadata2,\n",
    "                   \"Post_Metadata2\" : post_metadata2,\n",
    "                   \"Subreddit2\" : subreddit2,\n",
    "                   \"Score2\" : score2,\n",
    "                   \"Response2\" : response2,\n",
    "                   \"Dimension\" : dimension,\n",
    "                    }\n",
    "        annotations.append(example)\n",
    "            \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pairwise_message_definition_fewshot(annotations, dimension_):\n",
    "    few_shot_prompt_list = list()\n",
    "\n",
    "    for annotation in annotations:\n",
    "\n",
    "        title1 = annotation[\"Title1\"]\n",
    "        description1 = annotation[\"Description1\"] if annotation[\"Description1\"] == annotation[\"Description1\"] else \"\"\n",
    "        comment1 = annotation[\"Comment1\"]\n",
    "        title2 = annotation[\"Title2\"]\n",
    "        description2 = annotation[\"Description2\"] if annotation[\"Description2\"] == annotation[\"Description2\"] else \"\"\n",
    "        comment2 = annotation[\"Comment2\"]\n",
    "\n",
    "        template = None\n",
    "        dimension = None\n",
    "        pairwise_dimension = None\n",
    "        few_shot = None\n",
    "        if dimension_ == \"formality\":\n",
    "            template = prompts.casual_formal_definition\n",
    "            dimension = prompts.dimensions[1]\n",
    "            pairwise_dimension = prompts.pairwise_dimension[0]\n",
    "            few_shot = prompts.few_shot_pairwise_formality \n",
    "\n",
    "        elif dimension_ == \"supportiveness\":\n",
    "            template = prompts.supportive_toxic_definition\n",
    "            dimension = prompts.dimensions[2]\n",
    "            pairwise_dimension = prompts.pairwise_dimension[1]\n",
    "            few_shot = prompts.few_shot_pairwise_supportive \n",
    "\n",
    "        elif dimension_ == \"sarcasm\":\n",
    "            template = prompts.genuine_sarcasm_definition\n",
    "            dimension = prompts.dimensions[3]\n",
    "            pairwise_dimension = prompts.pairwise_dimension[2]\n",
    "            few_shot = prompts.few_shot_pairwise_genuine\n",
    "\n",
    "        elif dimension_ == \"politeness\":\n",
    "            template = prompts.rude_polite_definition\n",
    "            dimension = prompts.dimensions[4]\n",
    "            pairwise_dimension = prompts.pairwise_dimension[3]\n",
    "            few_shot = prompts.few_shot_pairwise_polite \n",
    "\n",
    "        elif dimension_ == \"humor\":\n",
    "            template = prompts.humor_serious_definition\n",
    "            dimension = prompts.dimensions[5]\n",
    "            pairwise_dimension = prompts.pairwise_dimension[4]\n",
    "            few_shot = prompts.few_shot_pairwise_humor \n",
    "\n",
    "        system_content = prompts.prompt_system_pairwise\n",
    "        user_content = prompts.prompt_pairwise_definition_few_shot     \n",
    "        user_content = user_content.replace(\"[DIMENSION]\", dimension)\n",
    "        user_content = user_content.replace(\"[DIMENSION_PAIRWISE]\", pairwise_dimension)\n",
    "        user_content = user_content.replace(\"[DIMENSION_DEFINITION]\", template)\n",
    "        user_content = user_content.replace(\"[FEW-SHOT]\", few_shot)\n",
    "\n",
    "\n",
    "        user_content = user_content.replace(\"[TITLE1]\", title1)\n",
    "        user_content = user_content.replace(\"[DESCRIPTION1]\", description1)\n",
    "        user_content = user_content.replace(\"[COMMENT1]\", comment1)\n",
    "        user_content = user_content.replace(\"[TITLE2]\", title2)\n",
    "        user_content = user_content.replace(\"[DESCRIPTION2]\", description2)\n",
    "        user_content = user_content.replace(\"[COMMENT2]\", comment2)\n",
    "        #user_content = user_content.replace(\"[RATING]\", str(rating))\n",
    "\n",
    "        messages =  [[{\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content}], title1, description1, comment1,\n",
    "                     annotation[\"Comment_Metadata1\"], annotation[\"Post_Metadata1\"],\n",
    "                     annotation[\"Subreddit1\"], annotation[\"Score1\"], annotation[\"Response1\"],\n",
    "                     title2, description2, comment2,\n",
    "                     annotation[\"Comment_Metadata2\"], annotation[\"Post_Metadata2\"],\n",
    "                     annotation[\"Subreddit2\"], annotation[\"Score2\"], annotation[\"Response2\"], annotation[\"Dimension\"]]\n",
    "        few_shot_prompt_list.append((messages))\n",
    "    return few_shot_prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary_gpt4_synthetic_data(dictionary, dimension, topic):\n",
    "    # save dictionary to sampled_comments_and_submissions.pkl file\n",
    "    with open(SYNTHETIC_DATA_DIRECTORY + topic + \"_\" + dimension + '_synthetic_data.pkl', 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "        print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating response from gpt 3.5\n",
    "def get_response(messages, model_name, temperature):\n",
    "    ct, num_tokens, num_completion_tokens, num_prompt_tokens = 0, 0, 0, 0\n",
    "    while ct < 3:\n",
    "        ct += 1\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=512,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            num_tokens += response.usage.total_tokens\n",
    "            num_completion_tokens += response.usage.completion_tokens\n",
    "            num_prompt_tokens += response.usage.prompt_tokens\n",
    "            \n",
    "            return response, num_tokens, num_completion_tokens, num_prompt_tokens\n",
    "        except Exception as e:\n",
    "            print(\"Error\")\n",
    "            print(e)\n",
    "            #logging.error(traceback.format_exc())\n",
    "    return None, num_tokens, num_completion_tokens, num_prompt_tokens\n",
    "\n",
    "def evaluate_gpt_rating(prompts, model_name, temperature, topic, dimension):\n",
    "    failed, usage, prompt_usage, completion_tokens = 0, 0, 0, 0\n",
    "    rated_comments = dict()\n",
    "    \n",
    "    prompts_rated = list()\n",
    "    for i, prompt_tuple in enumerate(prompts):\n",
    "        prompt_message = prompt_tuple[0]\n",
    "        #print(prompt_message)\n",
    "        response, num_tokens, num_completion_tokens, num_prompt_tokens = get_response(prompt_message, model_name, temperature)\n",
    "        try: \n",
    "            rewrite = response.choices[0].message.content.strip()\n",
    "        except:\n",
    "            rewrite = \"[API_ERROR]\"\n",
    "            failed += 1\n",
    "        usage += num_tokens\n",
    "        prompt_usage += num_prompt_tokens\n",
    "        completion_tokens += num_completion_tokens\n",
    "\n",
    "\n",
    "        prompt_tuple.insert(0, rewrite)\n",
    "        prompts_rated.append(prompt_tuple)\n",
    "\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            rated_comments[dimension] = prompts_rated\n",
    "            print(\"Number of prompts completed: \" + str(i))\n",
    "            save_dictionary_gpt4_synthetic_data(rated_comments, dimension, topic)\n",
    "\n",
    "\n",
    "    rated_comments[dimension] = prompts_rated\n",
    "    save_dictionary_gpt4_synthetic_data(rated_comments, dimension, topic)\n",
    "        \n",
    "    print(\"Total Prompt Token Usage: \" + str(num_prompt_tokens))\n",
    "    print(\"Total Completion Token Usage: \" + str(num_completion_tokens))\n",
    "    return rated_comments, failed, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating_and_organize(file_name, save_to_csv_name):\n",
    "    dict_ = dict()\n",
    "    with open(SYNTHETIC_DATA_DIRECTORY + file_name, 'rb') as f:\n",
    "        dict_ = pickle.load(f)\n",
    "\n",
    "    prediction_list = []\n",
    "    response_list = []\n",
    "    pairwise_prompt_list = []\n",
    "    title1_list = []\n",
    "    description1_list = []\n",
    "    comment1 = []\n",
    "    comment_metadata1 = []\n",
    "    post_metadata1 = []\n",
    "    subreddit1 = []\n",
    "    rated_score1 = []\n",
    "    rated_score_response1 = []\n",
    "    title2_list = []\n",
    "    description2_list = []\n",
    "    comment2 = []\n",
    "    comment_metadata2 = []\n",
    "    post_metadata2 = []\n",
    "    subreddit2 = []\n",
    "    rated_score2 = []\n",
    "    rated_score_response2 = []\n",
    "    dimension_list = []\n",
    "\n",
    "    for dimension, prompt_tuples in dict_.items():\n",
    "        for prompt_tuple in prompt_tuples:\n",
    "            response = prompt_tuple[0]\n",
    "            \n",
    "            try:\n",
    "                prediction = ''.join(response.split(\"{\")[1].split(\"}\")[0])\n",
    "            except:\n",
    "                print(response)\n",
    "                print(prompt_tuple[1])\n",
    "                continue\n",
    "            \n",
    "            prediction_list.append(prediction)\n",
    "            response_list.append(response)\n",
    "            pairwise_prompt_list.append(prompt_tuple[1])\n",
    "            title1_list.append(prompt_tuple[2])\n",
    "            description1_list.append(prompt_tuple[3])\n",
    "            comment1.append(prompt_tuple[4])\n",
    "            comment_metadata1.append(prompt_tuple[5])\n",
    "            post_metadata1.append(prompt_tuple[6])\n",
    "            subreddit1.append(prompt_tuple[7])\n",
    "            rated_score1.append(prompt_tuple[8])\n",
    "            rated_score_response1.append(prompt_tuple[9])\n",
    "            title2_list.append(prompt_tuple[10])\n",
    "            description2_list.append(prompt_tuple[11])\n",
    "            comment2.append(prompt_tuple[12])\n",
    "            comment_metadata2.append(prompt_tuple[13])\n",
    "            post_metadata2.append(prompt_tuple[14])\n",
    "            subreddit2.append(prompt_tuple[15])\n",
    "            rated_score2.append(prompt_tuple[16])\n",
    "            rated_score_response2.append(prompt_tuple[17])\n",
    "            dimension_list.append(prompt_tuple[18])\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df[\"synthetic_label\"] = prediction_list\n",
    "    df[\"gpt4_synthetic_label_response\"] = response_list\n",
    "    df[\"gpt4_synthetic_label_prompt\"] = pairwise_prompt_list\n",
    "    df[\"title1\"] = title1_list\n",
    "    df[\"description1\"] = description1_list\n",
    "    df[\"comment1\"] = comment1\n",
    "    df[\"comment1_metadata\"] = comment_metadata1\n",
    "    df[\"post1_metadata\"] = post_metadata1\n",
    "    df[\"subreddit1\"] = subreddit1\n",
    "    df[\"gpt3-5_rated_score1\"] = rated_score1\n",
    "    df[\"gpt3-5_rated_score1_response\"] = rated_score_response1\n",
    "    df[\"title2\"] = title2_list\n",
    "    df[\"description2\"] = description2_list\n",
    "    df[\"comment2\"] = comment2\n",
    "    df[\"comment2_metadata\"] = comment_metadata2\n",
    "    df[\"post2_metadata\"] = post_metadata2\n",
    "    df[\"subreddit2\"] = subreddit2\n",
    "    df[\"gpt3-5_rated_score2\"] = rated_score2\n",
    "    df[\"gpt3-5_rated_score2_response\"] = rated_score_response2\n",
    "    df[\"dimension\"] = dimension_list\n",
    "    \n",
    "    df.to_csv(SYNTHETIC_DATA_DIRECTORY + save_to_csv_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORTIVE-TOXIC\n",
      "RUDE-POLITE\n",
      "HUMOR-SERIOUS\n",
      "GENUINE-SARCASM\n",
      "CASUAL-FORMAL\n"
     ]
    }
   ],
   "source": [
    "# creating prompts\n",
    "dimensions = {'SUPPORTIVE-TOXIC' : \"supportiveness\", 'CASUAL-FORMAL' : \"formality\", 'GENUINE-SARCASM': \"sarcasm\", 'RUDE-POLITE' : \"politeness\", 'HUMOR-SERIOUS': \"humor\"}\n",
    "\n",
    "dimension_to_prompts = dict()\n",
    "for dimension, pair_order_list in dimension_sampled.items():\n",
    "    print(dimension)\n",
    "    annotations = collect_annotation_batch_pairwise_tuples(pair_order_list)\n",
    "    prompt_list = construct_pairwise_message_definition_fewshot(annotations, dimensions[dimension])\n",
    "    dimension_to_prompts[dimension] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts completed: 0\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 10\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 20\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 30\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 40\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 50\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 60\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 70\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 80\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 90\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 100\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 110\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 120\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 130\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 140\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 150\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 160\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 170\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 180\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 190\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 200\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 210\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 220\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 230\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 240\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 250\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 260\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 270\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 280\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 290\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 300\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 310\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 320\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 330\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 340\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 350\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 360\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 370\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 380\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 390\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 400\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 410\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 420\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 430\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 440\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 450\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 460\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 470\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 480\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 490\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 500\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 510\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 520\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 530\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 540\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 550\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 560\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 570\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 580\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 590\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 600\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 610\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 620\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 630\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 640\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 650\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 660\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 670\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 680\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 690\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 700\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 710\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 720\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 730\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 740\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 750\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 760\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 770\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 780\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 790\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 800\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 810\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 820\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 830\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 840\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 850\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 860\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 870\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 880\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 890\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 900\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 910\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 920\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 930\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 940\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 950\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 960\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 970\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 980\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 990\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1000\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1010\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1020\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1030\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1040\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1050\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1060\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1070\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1080\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1090\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1100\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1110\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1120\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1130\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1140\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1150\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1160\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1170\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1180\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1190\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1200\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1210\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1220\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1230\n",
      "dictionary saved successfully to file\n",
      "Number of prompts completed: 1240\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "Total Prompt Token Usage: 795\n",
      "Total Completion Token Usage: 92\n",
      "Total failed: 0\n",
      "Total usage: 1820878\n"
     ]
    }
   ],
   "source": [
    "# creating synthetic labels using GPT4, repeat this for various norm dimensions\n",
    "model_name = \"gpt-4\"\n",
    "temperature = 0.2\n",
    "topic = \"finance\"\n",
    "dimension_ = dimensions_[0]\n",
    "\n",
    "rated_comments, failed, usage = evaluate_gpt_rating(dimension_to_prompts[dimension_], model_name, temperature, topic, dimension_)\n",
    "print(\"Total failed: \" + str(failed))\n",
    "print(\"Total usage: \" + str(usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rating_and_organize(\"finance_SUPPORTIVE-TOXIC_synthetic_data.pkl\", \"finance_supportive_toxic_synthetic_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
